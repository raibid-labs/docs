<!DOCTYPE html>
<html lang="en" dir="ltr"><head><title>OSS_DEPLOYMENT_STRATEGY</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;family=IBM Plex Mono:wght@400;600&amp;display=swap"/><link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin="anonymous"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="Raibid Labs Documentation"/><meta property="og:title" content="OSS_DEPLOYMENT_STRATEGY"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="OSS_DEPLOYMENT_STRATEGY"/><meta name="twitter:description" content="Sparky OSS Deployment Strategy: DGX Spark Infrastructure Analysis Date: 2025-11-13 Status: Ready for Implementation Project: Sparky - Git Activity Summarization with 100% OSS Stack Executive Summary A fully operational, 100% open-source stack for Sparky is readily available through the DGX Spark Pla..."/><meta property="og:description" content="Sparky OSS Deployment Strategy: DGX Spark Infrastructure Analysis Date: 2025-11-13 Status: Ready for Implementation Project: Sparky - Git Activity Summarization with 100% OSS Stack Executive Summary A fully operational, 100% open-source stack for Sparky is readily available through the DGX Spark Pla..."/><meta property="og:image:alt" content="Sparky OSS Deployment Strategy: DGX Spark Infrastructure Analysis Date: 2025-11-13 Status: Ready for Implementation Project: Sparky - Git Activity Summarization with 100% OSS Stack Executive Summary A fully operational, 100% open-source stack for Sparky is readily available through the DGX Spark Pla..."/><meta property="twitter:domain" content="raibid-labs.github.io/docs"/><meta property="og:url" content="https://raibid-labs.github.io/docs/projects/sparky/docs/OSS_DEPLOYMENT_STRATEGY"/><meta property="twitter:url" content="https://raibid-labs.github.io/docs/projects/sparky/docs/OSS_DEPLOYMENT_STRATEGY"/><link rel="icon" href="../../../static/icon.png"/><meta name="description" content="Sparky OSS Deployment Strategy: DGX Spark Infrastructure Analysis Date: 2025-11-13 Status: Ready for Implementation Project: Sparky - Git Activity Summarization with 100% OSS Stack Executive Summary A fully operational, 100% open-source stack for Sparky is readily available through the DGX Spark Pla..."/><meta name="generator" content="Quartz"/><link href="../../../index.css" rel="stylesheet" type="text/css" spa-preserve/><style>.expand-button {
  position: absolute;
  display: flex;
  float: right;
  padding: 0.4rem;
  margin: 0.3rem;
  right: 0;
  color: var(--gray);
  border-color: var(--dark);
  background-color: var(--light);
  border: 1px solid;
  border-radius: 5px;
  opacity: 0;
  transition: 0.2s;
}
.expand-button > svg {
  fill: var(--light);
  filter: contrast(0.3);
}
.expand-button:hover {
  cursor: pointer;
  border-color: var(--secondary);
}
.expand-button:focus {
  outline: 0;
}

pre:hover > .expand-button {
  opacity: 1;
  transition: 0.2s;
}

#mermaid-container {
  position: fixed;
  contain: layout;
  z-index: 999;
  left: 0;
  top: 0;
  width: 100vw;
  height: 100vh;
  overflow: hidden;
  display: none;
  backdrop-filter: blur(4px);
  background: rgba(0, 0, 0, 0.5);
}
#mermaid-container.active {
  display: inline-block;
}
#mermaid-container > #mermaid-space {
  border: 1px solid var(--lightgray);
  background-color: var(--light);
  border-radius: 5px;
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  height: 80vh;
  width: 80vw;
  overflow: hidden;
}
#mermaid-container > #mermaid-space > .mermaid-content {
  padding: 2rem;
  position: relative;
  transform-origin: 0 0;
  transition: transform 0.1s ease;
  overflow: visible;
  min-height: 200px;
  min-width: 200px;
}
#mermaid-container > #mermaid-space > .mermaid-content pre {
  margin: 0;
  border: none;
}
#mermaid-container > #mermaid-space > .mermaid-content svg {
  max-width: none;
  height: auto;
}
#mermaid-container > #mermaid-space > .mermaid-controls {
  position: absolute;
  bottom: 20px;
  right: 20px;
  display: flex;
  gap: 8px;
  padding: 8px;
  background: var(--light);
  border: 1px solid var(--lightgray);
  border-radius: 6px;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  z-index: 2;
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button {
  display: flex;
  align-items: center;
  justify-content: center;
  width: 32px;
  height: 32px;
  padding: 0;
  border: 1px solid var(--lightgray);
  background: var(--light);
  color: var(--dark);
  border-radius: 4px;
  cursor: pointer;
  font-size: 16px;
  font-family: var(--bodyFont);
  transition: all 0.2s ease;
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:hover {
  background: var(--lightgray);
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:active {
  transform: translateY(1px);
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:nth-child(2) {
  width: auto;
  padding: 0 12px;
  font-size: 14px;
}
/*# sourceMappingURL=data:application/json;charset=utf-8;base64,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 */</style><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../../../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../../../static/contentIndex.json").then(data => data.json())</script><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="https://raibid-labs.github.io/docs/index.xml"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image" content="https://raibid-labs.github.io/docs/projects/sparky/docs/OSS_DEPLOYMENT_STRATEGY-og-image.webp"/><meta property="og:image:url" content="https://raibid-labs.github.io/docs/projects/sparky/docs/OSS_DEPLOYMENT_STRATEGY-og-image.webp"/><meta name="twitter:image" content="https://raibid-labs.github.io/docs/projects/sparky/docs/OSS_DEPLOYMENT_STRATEGY-og-image.webp"/><meta property="og:image:type" content="image/.webp"/></head><body data-slug="projects/sparky/docs/OSS_DEPLOYMENT_STRATEGY"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href="../../..">Raibid Labs Documentation</a></h2><div class="spacer mobile-only"></div><div class="flex-component" style="flex-direction: row; flex-wrap: nowrap; gap: 1rem;"><div style="flex-grow: 1; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><div class="search"><button class="search-button"><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg><p>Search</p></button><div class="search-container"><div class="search-space"><input autocomplete="off" class="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div class="search-layout" data-preview="true"></div></div></div></div></div><div style="flex-grow: 0; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><button class="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div style="flex-grow: 0; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><button class="readermode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="readerIcon" fill="currentColor" stroke="currentColor" stroke-width="0.2" stroke-linecap="round" stroke-linejoin="round" width="64px" height="64px" viewBox="0 0 24 24" aria-label="Reader mode"><title>Reader mode</title><g transform="translate(-1.8, -1.8) scale(1.15, 1.2)"><path d="M8.9891247,2.5 C10.1384702,2.5 11.2209868,2.96705384 12.0049645,3.76669482 C12.7883914,2.96705384 13.8709081,2.5 15.0202536,2.5 L18.7549359,2.5 C19.1691495,2.5 19.5049359,2.83578644 19.5049359,3.25 L19.5046891,4.004 L21.2546891,4.00457396 C21.6343849,4.00457396 21.9481801,4.28672784 21.9978425,4.6528034 L22.0046891,4.75457396 L22.0046891,20.25 C22.0046891,20.6296958 21.7225353,20.943491 21.3564597,20.9931534 L21.2546891,21 L2.75468914,21 C2.37499337,21 2.06119817,20.7178461 2.01153575,20.3517706 L2.00468914,20.25 L2.00468914,4.75457396 C2.00468914,4.37487819 2.28684302,4.061083 2.65291858,4.01142057 L2.75468914,4.00457396 L4.50368914,4.004 L4.50444233,3.25 C4.50444233,2.87030423 4.78659621,2.55650904 5.15267177,2.50684662 L5.25444233,2.5 L8.9891247,2.5 Z M4.50368914,5.504 L3.50468914,5.504 L3.50468914,19.5 L10.9478955,19.4998273 C10.4513189,18.9207296 9.73864328,18.5588115 8.96709342,18.5065584 L8.77307039,18.5 L5.25444233,18.5 C4.87474657,18.5 4.56095137,18.2178461 4.51128895,17.8517706 L4.50444233,17.75 L4.50368914,5.504 Z M19.5049359,17.75 C19.5049359,18.1642136 19.1691495,18.5 18.7549359,18.5 L15.2363079,18.5 C14.3910149,18.5 13.5994408,18.8724714 13.0614828,19.4998273 L20.5046891,19.5 L20.5046891,5.504 L19.5046891,5.504 L19.5049359,17.75 Z M18.0059359,3.999 L15.0202536,4 L14.8259077,4.00692283 C13.9889509,4.06666544 13.2254227,4.50975805 12.7549359,5.212 L12.7549359,17.777 L12.7782651,17.7601316 C13.4923805,17.2719483 14.3447024,17 15.2363079,17 L18.0059359,16.999 L18.0056891,4.798 L18.0033792,4.75457396 L18.0056891,4.71 L18.0059359,3.999 Z M8.9891247,4 L6.00368914,3.999 L6.00599909,4.75457396 L6.00599909,4.75457396 L6.00368914,4.783 L6.00368914,16.999 L8.77307039,17 C9.57551536,17 10.3461406,17.2202781 11.0128313,17.6202194 L11.2536891,17.776 L11.2536891,5.211 C10.8200889,4.56369974 10.1361548,4.13636104 9.37521067,4.02745763 L9.18347055,4.00692283 L8.9891247,4 Z"></path></g></svg></button></div></div><div class="explorer" data-behavior="link" data-collapsed="collapsed" data-savestate="true" data-data-fns="{&quot;order&quot;:[&quot;filter&quot;,&quot;map&quot;,&quot;sort&quot;],&quot;sortFn&quot;:&quot;(a,b)=>!a.isFolder&amp;&amp;!b.isFolder||a.isFolder&amp;&amp;b.isFolder?a.displayName.localeCompare(b.displayName,void 0,{numeric:!0,sensitivity:\&quot;base\&quot;}):!a.isFolder&amp;&amp;b.isFolder?1:-1&quot;,&quot;filterFn&quot;:&quot;node=>node.slugSegment!==\&quot;tags\&quot;&quot;,&quot;mapFn&quot;:&quot;node=>node&quot;}"><button type="button" class="explorer-toggle mobile-explorer hide-until-loaded" data-mobile="true" aria-controls="explorer-524"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide-menu"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg></button><button type="button" class="title-button explorer-toggle desktop-explorer" data-mobile="false" aria-expanded="true"><h2>Explorer</h2><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="explorer-524" class="explorer-content" aria-expanded="false" role="group"><ul class="explorer-ul overflow" id="list-0"><li class="overflow-end"></li></ul></div><template id="template-file"><li><a href="#"></a></li></template><template id="template-folder"><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div><button class="folder-button"><span class="folder-title"></span></button></div></div><div class="folder-outer"><ul class="content"></ul></div></li></template></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../../../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../projects/">Projects</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../projects/sparky/">sparky</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../projects/sparky/docs/">docs</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>OSS_DEPLOYMENT_STRATEGY</a></div></nav><h1 class="article-title">OSS_DEPLOYMENT_STRATEGY</h1><p show-comma="true" class="content-meta"><time datetime="2025-11-16T03:15:16.134Z">Nov 16, 2025</time><span>11 min read</span></p></div></div><article class="popover-hint"><h1 id="sparky-oss-deployment-strategy-dgx-spark-infrastructure-analysis">Sparky OSS Deployment Strategy: DGX Spark Infrastructure Analysis<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#sparky-oss-deployment-strategy-dgx-spark-infrastructure-analysis" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p><strong>Date:</strong> 2025-11-13<br/>
<strong>Status:</strong> Ready for Implementation<br/>
<strong>Project:</strong> Sparky - Git Activity Summarization with 100% OSS Stack</p>
<hr/>
<h2 id="executive-summary">Executive Summary<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#executive-summary" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>A fully operational, 100% open-source stack for Sparky is readily available through the DGX Spark Playbooks infrastructure. The system can run on hardware with DGX Spark compatibility (NVIDIA Blackwell GPU, ARM64 architecture) or be adapted to standard x86_64 systems with NVIDIA GPUs. <strong>Zero external API costs</strong> are achievable using containerized Ollama or vLLM inference servers with self-hosted models.</p>
<h3 id="key-finding">Key Finding<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#key-finding" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>The <code>dgx-spark-playbooks</code> repository contains 27+ production-ready playbooks with complete Docker/Kubernetes deployment patterns, model serving infrastructure, and orchestration examples that can be directly applied to Sparky.</p>
<hr/>
<h2 id="1-infrastructure-landscape">1. Infrastructure Landscape<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#1-infrastructure-landscape" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="11-available-hardware--gpu-resources">1.1 Available Hardware &amp; GPU Resources<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#11-available-hardware--gpu-resources" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>Current System:</strong></p>
<ul>
<li>GPU: NVIDIA GB10 (Blackwell architecture)</li>
<li>VRAM: Not directly visible in current context, but DGX Spark typically has 128GB unified memory</li>
<li>Storage: 3.7TB available on root partition</li>
<li>Docker Version: 28.3.3 (fully configured and operational)</li>
<li>Kubernetes: K3s cluster running (k3d-raibid-ci) with registry</li>
</ul>
<p><strong>Infrastructure Already In Place:</strong></p>
<pre><code>K3s Cluster (Active):
  - k3d-raibid-ci (cluster name)
  - 1x manager node + worker nodes
  - Internal registry at localhost:5000
  - LoadBalancer proxy configured
  - Perfect for containerized workloads
</code></pre>
<h3 id="12-containerization--orchestration">1.2 Containerization &amp; Orchestration<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#12-containerization--orchestration" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>Docker Status:</strong> Ready</p>
<ul>
<li>Version 28.3.3 (modern, supports GPU passthrough)</li>
<li>NVIDIA Container Toolkit configured</li>
<li>Can run GPU-accelerated containers directly</li>
</ul>
<p><strong>Kubernetes Status:</strong> Active K3s cluster</p>
<ul>
<li>3 nodes visible (manager + 2 worker-like proxies)</li>
<li>Internal registry for image caching</li>
<li>Can deploy multi-container systems at scale</li>
<li>No external Kubernetes API required (fully self-contained)</li>
</ul>
<hr/>
<h2 id="2-llm-inference-options-100-oss">2. LLM Inference Options (100% OSS)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#2-llm-inference-options-100-oss" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="21-ollama-simplest-path">2.1 Ollama (Simplest Path)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#21-ollama-simplest-path" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>Status:</strong> Ready to deploy via playbook<br/>
<strong>Location:</strong> <code>/home/beengud/raibid-labs/dgx-spark-playbooks/nvidia/ollama/</code></p>
<p><strong>Capabilities:</strong></p>
<ul>
<li>Run local LLMs without API keys</li>
<li>GPU-accelerated inference (CUDA/NVIDIA GPU support)</li>
<li>REST API compatible interface (OpenAI-like)</li>
<li>Support for 100+ models from ollama.com library</li>
<li>Zero external dependencies after initial setup</li>
</ul>
<p><strong>Deployment:</strong></p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="dockerfile" data-theme="github-light one-dark-pro"><code data-language="dockerfile" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#61AFEF;">FROM</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> nvidia/cuda:12.0-base-ubuntu22.04</span></span>
<span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#61AFEF;">RUN</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> curl -fsSL https://ollama.com/install.sh | sh</span></span>
<span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#61AFEF;">EXPOSE</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> 11434</span></span></code></pre></figure>
<p><strong>Models Available (OSS, no licensing):</strong></p>
<ul>
<li>Llama 2/3/3.1 (Meta - Open)</li>
<li>Phi 3.5/4 (Microsoft - Open)</li>
<li>Qwen 2.5/3 (Alibaba - Open)</li>
<li>Mistral (Open)</li>
<li>Deepseek (Open)</li>
<li>GPT-OSS-20B/120B (OpenAI - Open)</li>
</ul>
<p><strong>Performance Characteristics:</strong></p>
<ul>
<li>Llama 3.1 8B: ~30-50 tokens/sec (on DGX Spark with Blackwell)</li>
<li>Qwen 32B: ~10-20 tokens/sec (depending on context length)</li>
<li>GPT-OSS 120B: ~5-10 tokens/sec on single GPU (excellent quality)</li>
</ul>
<p><strong>Recommendation:</strong> Start here for Sparky - minimal setup, excellent for git summarization</p>
<h3 id="22-vllm-high-throughput-path">2.2 vLLM (High-Throughput Path)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#22-vllm-high-throughput-path" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>Status:</strong> Production-ready playbook available<br/>
<strong>Location:</strong> <code>/home/beengud/raibid-labs/dgx-spark-playbooks/nvidia/vllm/</code></p>
<p><strong>Capabilities:</strong></p>
<ul>
<li>Higher throughput than Ollama (batched inference)</li>
<li>Tensor parallelism across multiple GPUs</li>
<li>PagedAttention for memory efficiency</li>
<li>OpenAI-compatible API</li>
<li>Ray cluster support for multi-GPU distribution</li>
</ul>
<p><strong>Deployment Architecture:</strong></p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="yaml" data-theme="github-light one-dark-pro"><code data-language="yaml" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">Single Node</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">  docker run -p 8000:8000 --gpus all nvcr.io/nvidia/vllm:25.09-py3 \</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    vllm serve &quot;model-name&quot;</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">Multi-Node (Ray)</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">  - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">Head node on primary GPU</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">  - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">Worker nodes join cluster</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">  - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">Tensor parallelism across nodes</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">  - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">Automatic work distribution</span></span></code></pre></figure>
<p><strong>Performance Characteristics:</strong></p>
<ul>
<li>Single 8B model: 100+ tokens/sec sustained</li>
<li>Batched requests: 200-400 tokens/sec (dependent on batch size)</li>
<li>70B with tensor parallelism: 50+ tokens/sec</li>
<li>Memory efficient: Uses PagedAttention for long sequences</li>
</ul>
<p><strong>Recommendation:</strong> Use for high-volume production (if daily summaries need &lt;5min processing)</p>
<h3 id="23-tensorrt-llm-maximum-efficiency">2.3 TensorRT-LLM (Maximum Efficiency)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#23-tensorrt-llm-maximum-efficiency" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>Status:</strong> Full Docker Swarm multi-node deployment available<br/>
<strong>Location:</strong> <code>/home/beingud/raibid-labs/dgx-spark-playbooks/nvidia/trt-llm/</code></p>
<p><strong>Capabilities:</strong></p>
<ul>
<li>Optimized inference kernels (2-10x faster than PyTorch)</li>
<li>FP8 and NVFP4 quantization support</li>
<li>Tensor, pipeline, and sequence parallelism</li>
<li>OpenAI-compatible API</li>
<li>Docker Swarm orchestration for multi-node</li>
</ul>
<p><strong>Deployment Architecture:</strong></p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="yaml" data-theme="github-light one-dark-pro"><code data-language="yaml" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">Docker Swarm Cluster</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">  - </span><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">Manager node</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">coordinates requests</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">  - </span><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">Worker nodes</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">run inference with GPU</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">  - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">Multi-node support via MPI</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">  - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">Automatic GPU resource management</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">  - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">Health checks and restart policies</span></span></code></pre></figure>
<p><strong>Supported Models (Pre-quantized):</strong></p>
<ul>
<li>Llama 3.1 8B, 70B (FP8/NVFP4)</li>
<li>Qwen 3 8B-235B (NVFP4)</li>
<li>GPT-OSS 20B/120B (MXFP4)</li>
<li>Phi 4 multimodal (FP8/NVFP4)</li>
</ul>
<p><strong>Performance Characteristics:</strong></p>
<ul>
<li>8B model: 150+ tokens/sec (quantized)</li>
<li>70B model: 80+ tokens/sec (tensor parallel)</li>
<li>120B model: 20-30 tokens/sec (full accuracy)</li>
</ul>
<p><strong>Recommendation:</strong> For production Sparky with volume >100 summaries/day</p>
<hr/>
<h2 id="3-existing-deployment-patterns-ready-to-use">3. Existing Deployment Patterns (Ready to Use)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#3-existing-deployment-patterns-ready-to-use" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="31-pattern-1-text-to-knowledge-graph-txt2kg">3.1 Pattern 1: Text-to-Knowledge-Graph (txt2kg)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#31-pattern-1-text-to-knowledge-graph-txt2kg" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>Full Microservices Stack:</strong> <code>/home/beengud/raibid-labs/dgx-spark-playbooks/nvidia/txt2kg/</code></p>
<p><strong>Services Architecture:</strong></p>
<pre><code>┌─────────────────────────────────────────────────┐
│         txt2kg Frontend (Next.js)               │
│         Port: 3001                              │
└──────────┬──────────────────────────────────────┘
           │
    ┌──────┴──────┬─────────────┬────────────────┐
    │             │             │                │
┌───▼────┐  ┌────▼────┐  ┌─────▼────┐  ┌───────▼────┐
│ Ollama │  │ArangoDB │  │Sentence  │  │  Pinecone  │
│:11434  │  │ :8529   │  │Transform │  │  :5081     │
└────────┘  └─────────┘  │ :80      │  └────────────┘
                         └──────────┘
</code></pre>
<p><strong>Docker Compose Configuration:</strong></p>
<ul>
<li>6 services with health checks</li>
<li>GPU passthrough configured</li>
<li>Persistent volumes for models/data</li>
<li>Internal networking (no external internet after startup)</li>
</ul>
<p><strong>Relevant for Sparky:</strong></p>
<ul>
<li>Ollama integration example</li>
<li>Multi-service coordination</li>
<li>Health check patterns</li>
<li>Volume management for large models</li>
<li>GPU resource allocation</li>
</ul>
<h3 id="32-pattern-2-multi-agent-chatbot">3.2 Pattern 2: Multi-Agent Chatbot<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#32-pattern-2-multi-agent-chatbot" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>Full Backend + Frontend:</strong> <code>/home/beengud/raibid-labs/dgx-spark-playbooks/nvidia/multi-agent-chatbot/assets/</code></p>
<p><strong>Architecture:</strong></p>
<pre><code>┌──────────────────────────────────────────────────┐
│          Frontend (React/TypeScript)             │
│          Port: 3000                              │
└──────────┬───────────────────────────────────────┘
           │
┌──────────▼───────────────────────────────────────┐
│        Backend API (Python/FastAPI)              │
│        Port: 8000                                │
└──────────┬───────────────────────────────────────┘
           │
    ┌──────┼──────┬──────────┬──────────┐
    │      │      │          │          │
┌───▼──┐┌──▼──┐┌──▼───┐┌────▼───┐┌───▼──┐
│ LLM  ││Code ││ RAG  ││Milvus  ││Postgres
│Servers││ LLM ││ LLM  ││(Vector)││(State)
└──────┘└─────┘└──────┘└────────┘└──────┘
</code></pre>
<p><strong>Relevant for Sparky:</strong></p>
<ul>
<li>Multi-service orchestration pattern</li>
<li>PostgreSQL for state management</li>
<li>Milvus vector database (for semantic search)</li>
<li>Multiple LLM endpoints running in parallel</li>
<li>Docker Compose with health checks and dependencies</li>
</ul>
<h3 id="33-pattern-3-trt-llm-multi-node">3.3 Pattern 3: TRT-LLM Multi-Node<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#33-pattern-3-trt-llm-multi-node" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>Docker Swarm Orchestration:</strong> <code>/home/beengud/raibid-labs/dgx-spark-playbooks/nvidia/trt-llm/assets/</code></p>
<p><strong>Relevant for Sparky:</strong></p>
<ul>
<li>Docker Swarm setup (not just Compose)</li>
<li>Multi-GPU tensor parallelism</li>
<li>MPI-based distributed inference</li>
<li>Hostname file management for cluster</li>
<li>Resource reservation on GPUs</li>
<li>Restart policies and health checks</li>
</ul>
<hr/>
<h2 id="4-recommended-architecture-for-sparky-100-oss">4. Recommended Architecture for Sparky (100% OSS)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#4-recommended-architecture-for-sparky-100-oss" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="41-minimum-viable-deployment">4.1 Minimum Viable Deployment<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#41-minimum-viable-deployment" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>Tier 1: Simple (Can process 20-50 repos/day)</strong></p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="yaml" data-theme="github-light one-dark-pro"><code data-language="yaml" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># docker-compose.yml</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">version</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">'3.8'</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">services</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  ollama</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    image</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">ollama/ollama:latest</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    ports</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;11434:11434&quot;</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    volumes</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">ollama_data:/root/.ollama</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    environment</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">OLLAMA_FLASH_ATTENTION=1</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">OLLAMA_GPU_LAYERS=999</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">OLLAMA_GPU_MEMORY_FRACTION=0.9</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">OLLAMA_KV_CACHE_TYPE=q8_0</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    deploy</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      resources</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">        reservations</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">          devices</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">            - </span><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">driver</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">nvidia</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">              count</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">              capabilities</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">gpu</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    healthcheck</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      test</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;CMD&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;curl&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;-f&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;http://localhost:11434/api/tags&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      interval</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">30s</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      timeout</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">10s</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      retries</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">3</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  sparky-backend</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    build</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      context</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">.</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      dockerfile</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">Dockerfile</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    ports</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;8000:8000&quot;</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    environment</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">OLLAMA_API_URL=http://ollama:11434</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">OLLAMA_MODEL=llama3.1:8b</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    depends_on</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      ollama</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">        condition</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">service_healthy</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    volumes</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">./data:/app/data</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">volumes</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  ollama_data</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span></code></pre></figure>
<p><strong>Stack Components:</strong></p>
<ul>
<li>Ollama (LLM inference) - 1 container</li>
<li>Sparky backend (git processing) - 1 container</li>
<li>Network bridge for communication</li>
<li>Total: ~2-3GB RAM after models loaded</li>
</ul>
<p><strong>Cost:</strong></p>
<ul>
<li>Zero (open source only)</li>
<li>Compute: Whatever GPU you have</li>
<li>Storage: ~15GB for Llama 3.1 8B model</li>
</ul>
<h3 id="42-production-deployment">4.2 Production Deployment<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#42-production-deployment" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>Tier 2: Optimized (100+ repos/day)</strong></p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="yaml" data-theme="github-light one-dark-pro"><code data-language="yaml" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">services</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  vllm</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    image</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">nvcr.io/nvidia/vllm:25.09-py3</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    command</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">></span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">      vllm serve meta-llama/Llama-3.1-70B-Instruct</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">      --max_model_len 2048</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">      --tensor-parallel-size 2</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">      --max_num_seqs 16</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    ports</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;8000:8000&quot;</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    environment</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">VLLM_GPU_MEMORY_UTILIZATION=0.85</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">VLLM_ENABLE_PREFIX_CACHING=1</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    volumes</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">hf_models:/root/.cache/huggingface</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  sparky-processor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    build</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">./processor</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    environment</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">LLM_API_URL=http://vllm:8000/v1</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">BATCH_SIZE=16</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">WORKER_THREADS=4</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    depends_on</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">vllm</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    volumes</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">./data:/app/data</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  postgres</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    image</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">postgres:15-alpine</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    environment</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">POSTGRES_DB=sparky</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    volumes</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">postgres_data:/var/lib/postgresql/data</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  redis</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    image</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">redis:7-alpine</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    volumes</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">      - </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">redis_data:/data</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">volumes</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  hf_models</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  postgres_data</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  redis_data</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span></code></pre></figure>
<p><strong>Stack Components:</strong></p>
<ul>
<li>vLLM (high-throughput inference)</li>
<li>PostgreSQL (processed summaries, metadata)</li>
<li>Redis (task queue, caching)</li>
<li>Sparky processor (orchestration)</li>
<li>Monitoring/logging (optional)</li>
</ul>
<p><strong>Capacity:</strong></p>
<ul>
<li>100-200 repositories</li>
<li>Daily summary generation</li>
<li>10-15 minute total pipeline</li>
<li>One processor worker (scales horizontally)</li>
</ul>
<h3 id="43-enterprise-deployment">4.3 Enterprise Deployment<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#43-enterprise-deployment" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>Tier 3: Distributed (1000+ repos)</strong></p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="yaml" data-theme="github-light one-dark-pro"><code data-language="yaml" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">services</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # Use TRT-LLM with Docker Swarm</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # Multi-node tensor parallelism</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # Load balancing via haproxy or nginx</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # Distributed task queue (Celery + Redis)</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # Prometheus + Grafana monitoring</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # PostgreSQL with replication</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # Vector DB for semantic search</span></span></code></pre></figure>
<p><strong>Pattern:</strong> Docker Swarm (already configured in environment)</p>
<ul>
<li>Head node: API gateway + task scheduler</li>
<li>Worker nodes: vLLM/TRT-LLM services</li>
<li>External: PostgreSQL, Redis, monitoring</li>
</ul>
<hr/>
<h2 id="5-model-selection-for-sparky">5. Model Selection for Sparky<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#5-model-selection-for-sparky" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="51-recommended-models-by-use-case">5.1 Recommended Models (By Use Case)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#51-recommended-models-by-use-case" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>For Git Commit Summarization (Best Quality):</strong></p>








































<div class="table-container"><table><thead><tr><th>Model</th><th>Size</th><th>Speed</th><th>Quality</th><th>Recommended</th></tr></thead><tbody><tr><td>Llama 3.1 8B</td><td>8B</td><td>Very Fast</td><td>Good</td><td>Start here</td></tr><tr><td>GPT-OSS 20B</td><td>20B</td><td>Fast</td><td>Excellent</td><td>Production</td></tr><tr><td>Qwen 3 32B</td><td>32B</td><td>Medium</td><td>Excellent</td><td>Preferred</td></tr><tr><td>Llama 3.1 70B</td><td>70B</td><td>Slow</td><td>Outstanding</td><td>Gold standard</td></tr></tbody></table></div>
<p><strong>Recommendation:</strong> Start with Llama 3.1 8B, upgrade to Qwen 3 32B for production.</p>
<h3 id="52-model-performance-on-dgx-spark">5.2 Model Performance on DGX Spark<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#52-model-performance-on-dgx-spark" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Based on playbook examples and unified memory architecture:</p>
<pre><code>Model                    | GPU Memory | Throughput      | Quality
Llama 3.1 8B (FP16)      | 18GB       | 60 tok/s        | Good
Llama 3.1 8B (FP8)       | 10GB       | 80 tok/s        | Good
Qwen 3 32B (NVFP4)       | 12GB       | 40 tok/s        | Excellent
GPT-OSS 20B (MXFP4)      | 20GB       | 45 tok/s        | Excellent
Llama 3.1 70B (tensor-par)| 64GB      | 50 tok/s        | Outstanding
</code></pre>
<p><strong>DGX Spark Advantage:</strong> 128GB unified memory means you can run:</p>
<ul>
<li>Primary model (20-70GB)</li>
<li>Embedding model (2-4GB)</li>
<li>Embedding index (in-memory)</li>
<li>All simultaneously without swapping</li>
</ul>
<hr/>
<h2 id="6-integration-points-with-existing-infrastructure">6. Integration Points with Existing Infrastructure<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#6-integration-points-with-existing-infrastructure" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="61-git-data-collection-unchanged">6.1 Git Data Collection (Unchanged)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#61-git-data-collection-unchanged" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="python" data-theme="github-light one-dark-pro"><code data-language="python" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Current approach remains valid:</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 1. GitHub GraphQL API (rate limited but free)</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 2. Octokit client</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 3. raibid-cli for repo discovery</span></span></code></pre></figure>
<h3 id="62-llm-processing-pipeline-new">6.2 LLM Processing Pipeline (NEW)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#62-llm-processing-pipeline-new" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<pre><code>┌─────────────────┐
│   Git Data      │
│   (commits,     │
│    PRs, issues) │
└────────┬────────┘
         │
    ┌────▼──────┐
    │  Sparky   │
    │ Processor │ ← Python service (processes in batches)
    └────┬──────┘
         │
    ┌────▼────────────────────┐
    │  LLM Inference Server    │
    │  (Ollama/vLLM/TRT-LLM)   │
    │  Summarization Endpoint  │
    └────┬─────────────────────┘
         │
    ┌────▼────────────┐
    │  Summaries      │
    │  (JSON/Markdown)│
    └─────────────────┘
</code></pre>
<h3 id="63-storage-strategy">6.3 Storage Strategy<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#63-storage-strategy" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>For Sparky Data:</strong></p>
<ul>
<li><strong>Summaries:</strong> PostgreSQL (structured queries)</li>
<li><strong>Models:</strong> Docker volumes (persistent)</li>
<li><strong>Cache:</strong> Redis (processed commits)</li>
<li><strong>Artifacts:</strong> Local filesystem or S3-compatible (MinIO)</li>
</ul>
<hr/>
<h2 id="7-deployment-patterns-ready-to-copy">7. Deployment Patterns (Ready to Copy)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#7-deployment-patterns-ready-to-copy" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="71-health-checks-from-txt2kg">7.1 Health Checks (From txt2kg)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#71-health-checks-from-txt2kg" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="yaml" data-theme="github-light one-dark-pro"><code data-language="yaml" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">healthcheck</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  test</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;CMD&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;curl&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;-f&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;http://localhost:11434/api/tags&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  interval</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">30s</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  timeout</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">10s</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  retries</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">3</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  start_period</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">60s</span></span></code></pre></figure>
<h3 id="72-gpu-resource-configuration-from-trt-llm">7.2 GPU Resource Configuration (From TRT-LLM)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#72-gpu-resource-configuration-from-trt-llm" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="yaml" data-theme="github-light one-dark-pro"><code data-language="yaml" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">deploy</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  resources</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    reservations</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      devices</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">        - </span><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">driver</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">nvidia</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">          count</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # or 'all' for all GPUs</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">          capabilities</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">gpu</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]</span></span></code></pre></figure>
<h3 id="73-multi-container-networks-from-multi-agent-chatbot">7.3 Multi-Container Networks (From multi-agent-chatbot)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#73-multi-container-networks-from-multi-agent-chatbot" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="yaml" data-theme="github-light one-dark-pro"><code data-language="yaml" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">networks</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  default</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    driver</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">bridge</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    name</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">sparky-net</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Services connect via service_name:port</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># ollama:11434</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># postgres:5432</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># redis:6379</span></span></code></pre></figure>
<h3 id="74-volume-management-from-txt2kg">7.4 Volume Management (From txt2kg)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#74-volume-management-from-txt2kg" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="yaml" data-theme="github-light one-dark-pro"><code data-language="yaml" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">volumes</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  ollama_data</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    driver</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">local</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">  postgres_data</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span data-line><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    driver</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">local</span></span></code></pre></figure>
<hr/>
<h2 id="8-technology-stack-summary">8. Technology Stack Summary<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#8-technology-stack-summary" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="81-core-components">8.1 Core Components<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#81-core-components" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>











































































<div class="table-container"><table><thead><tr><th>Component</th><th>Tool</th><th>OSS</th><th>Status</th><th>Cost</th></tr></thead><tbody><tr><td><strong>LLM Inference</strong></td><td>Ollama/vLLM/TRT-LLM</td><td>Yes</td><td>Production-ready</td><td>$0</td></tr><tr><td><strong>Containerization</strong></td><td>Docker</td><td>Yes</td><td>Installed</td><td>$0</td></tr><tr><td><strong>Orchestration</strong></td><td>Docker Compose/Swarm/K3s</td><td>Yes</td><td>Available</td><td>$0</td></tr><tr><td><strong>Database</strong></td><td>PostgreSQL</td><td>Yes</td><td>Can add</td><td>$0</td></tr><tr><td><strong>Cache</strong></td><td>Redis</td><td>Yes</td><td>Can add</td><td>$0</td></tr><tr><td><strong>Message Queue</strong></td><td>Celery/RQ</td><td>Yes</td><td>Can add</td><td>$0</td></tr><tr><td><strong>Monitoring</strong></td><td>Prometheus/Grafana</td><td>Yes</td><td>Can add</td><td>$0</td></tr><tr><td><strong>Models</strong></td><td>HuggingFace (OSS)</td><td>Yes</td><td>Free</td><td>$0</td></tr><tr><td><strong>Git API</strong></td><td>GitHub GraphQL</td><td>Partial</td><td>Free tier</td><td>$0</td></tr></tbody></table></div>
<h3 id="82-external-dependencies-all-optional">8.2 External Dependencies (All Optional)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#82-external-dependencies-all-optional" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<pre><code>Required:
  ✓ Docker (already installed)
  ✓ GPU access (already available)
  ✓ Internet (for model downloads, one-time)

NOT Required:
  ✗ Anthropic API
  ✗ OpenAI API
  ✗ Any cloud service
  ✗ Any commercial license
</code></pre>
<hr/>
<h2 id="9-path-forward-for-sparky">9. Path Forward for Sparky<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#9-path-forward-for-sparky" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="phase-0-validation-days-1-2">Phase 0: Validation (Days 1-2)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#phase-0-validation-days-1-2" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="bash" data-theme="github-light one-dark-pro"><code data-language="bash" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 1. Deploy Ollama with Llama 3.1 8B</span></span>
<span data-line><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> compose</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -f</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ollama-compose.yml</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> up</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -d</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 2. Test inference</span></span>
<span data-line><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">curl</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> http://localhost:11434/api/chat</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -d</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> '</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">  {</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    &quot;model&quot;: &quot;llama3.1:8b&quot;,</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Summarize a git commit: fix: memory leak in cache module&quot;}],</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    &quot;stream&quot;: false</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">  }</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">'</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 3. Measure performance</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Record: latency, throughput, memory usage</span></span></code></pre></figure>
<h3 id="phase-1-integration-days-3-5">Phase 1: Integration (Days 3-5)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#phase-1-integration-days-3-5" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="bash" data-theme="github-light one-dark-pro"><code data-language="bash" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 1. Create Sparky processor service</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 2. Connect git data pipeline → Ollama</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 3. Batch processing with queue management</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 4. Store summaries in PostgreSQL</span></span></code></pre></figure>
<h3 id="phase-2-optimization-days-6-10">Phase 2: Optimization (Days 6-10)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#phase-2-optimization-days-6-10" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="bash" data-theme="github-light one-dark-pro"><code data-language="bash" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 1. Replace Ollama with vLLM for throughput</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 2. Implement batching (10-20 commits at once)</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 3. Add Redis caching for processed repos</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 4. Tune model parameters for speed</span></span></code></pre></figure>
<h3 id="phase-3-production-days-11-15">Phase 3: Production (Days 11-15)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#phase-3-production-days-11-15" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="bash" data-theme="github-light one-dark-pro"><code data-language="bash" data-theme="github-light one-dark-pro" style="display:grid;"><span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 1. Multi-worker deployment via Kubernetes/Swarm</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 2. Health checks and monitoring</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 3. Graceful scaling</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-light-font-style:inherit;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 4. Integration with existing raibid-labs tools</span></span></code></pre></figure>
<hr/>
<h2 id="10-key-advantages-of-this-approach">10. Key Advantages of This Approach<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#10-key-advantages-of-this-approach" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>✅ <strong>Zero Cost:</strong> All tools are open source, no API charges<br/>
✅ <strong>Ownership:</strong> Run locally, no data leaves your infrastructure<br/>
✅ <strong>Scalability:</strong> From single GPU to multi-node cluster<br/>
✅ <strong>Flexibility:</strong> Choose between Ollama (simple) → vLLM (fast) → TRT-LLM (optimized)<br/>
✅ <strong>Already Available:</strong> Patterns exist in dgx-spark-playbooks<br/>
✅ <strong>Proven:</strong> Used in production by NVIDIA for their own systems<br/>
✅ <strong>Community:</strong> Ollama, vLLM, TRT-LLM all have active communities</p>
<hr/>
<h2 id="11-file-reference-map">11. File Reference Map<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#11-file-reference-map" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="dgx-spark-playbooks-ready-to-use">DGX Spark Playbooks (Ready to Use)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#dgx-spark-playbooks-ready-to-use" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<pre><code>dgx-spark-playbooks/
├── nvidia/
│   ├── ollama/                      ← Start here
│   ├── open-webui/                  ← UI layer
│   ├── vllm/                        ← High throughput
│   ├── trt-llm/                     ← Maximum optimization
│   ├── txt2kg/                      ← Full stack example
│   │   └── docker-compose.yml       ← Copy this structure
│   ├── multi-agent-chatbot/         ← Multi-service pattern
│   └── ... (25+ other playbooks)
</code></pre>
<h3 id="sparky-project-structure-ready-for-implementation">Sparky Project Structure (Ready for Implementation)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#sparky-project-structure-ready-for-implementation" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<pre><code>sparky/
├── .github/
│   └── workflows/                   ← GitHub Actions
├── docker/
│   ├── Dockerfile.ollama            ← LLM service
│   ├── Dockerfile.processor         ← Sparky backend
│   └── docker-compose.yml           ← Orchestration
├── src/
│   ├── processor/                   ← Core logic
│   ├── integrations/                ← Git + LLM
│   └── models/                      ← Data structures
└── infrastructure/
    ├── kubernetes/                  ← K3s manifests (if scaling)
    └── monitoring/                  ← Prometheus/Grafana
</code></pre>
<hr/>
<h2 id="12-resource-requirements">12. Resource Requirements<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#12-resource-requirements" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="minimum-deployment">Minimum Deployment<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#minimum-deployment" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<pre><code>CPU:        2-4 cores
RAM:        16GB total (8GB CPU + 8GB GPU for model)
GPU:        8GB VRAM minimum
Storage:    50GB (15GB model + 35GB buffer)
Network:    1Gbps (for model download)
Time:       2-3 hours (first-time setup + model download)
</code></pre>
<h3 id="recommended-production">Recommended (Production)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#recommended-production" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<pre><code>CPU:        8-16 cores
RAM:        32-64GB (includes OS, models, buffer)
GPU:        24GB+ VRAM
Storage:    100-150GB
Network:    10Gbps if processing 1000+ repos/day
Time:       Full pipeline &lt; 15 minutes daily
</code></pre>
<hr/>
<h2 id="13-risk-assessment">13. Risk Assessment<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#13-risk-assessment" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>



































<div class="table-container"><table><thead><tr><th>Risk</th><th>Severity</th><th>Mitigation</th></tr></thead><tbody><tr><td>Model download fails</td><td>Low</td><td>Retry with huggingface-cli, use cache</td></tr><tr><td>GPU OOM</td><td>Medium</td><td>Switch to smaller model or quantized version</td></tr><tr><td>High latency</td><td>Low</td><td>Use batching or vLLM instead of Ollama</td></tr><tr><td>Data persistence</td><td>Low</td><td>Use Docker volumes, backup to NAS/S3</td></tr><tr><td>Network issues</td><td>Low</td><td>Cache models locally, pre-download before use</td></tr></tbody></table></div>
<hr/>
<h2 id="14-conclusion">14. Conclusion<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#14-conclusion" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p><strong>You have everything you need to build a fully functional, 100% open-source Sparky system.</strong></p>
<p>The DGX Spark Playbooks provide:</p>
<ul>
<li>Battle-tested deployment patterns</li>
<li>Real-world docker-compose configurations</li>
<li>GPU optimization techniques</li>
<li>Multi-node orchestration examples</li>
<li>Health checks and resilience patterns</li>
</ul>
<p><strong>Recommended Action:</strong></p>
<ol>
<li>Start with Ollama + simple Docker Compose</li>
<li>Validate with 10-20 repositories</li>
<li>Upgrade to vLLM if throughput insufficient</li>
<li>Scale to multi-node if processing 1000+ repositories</li>
</ol>
<p><strong>Timeline: 15 days</strong> to production-ready system (matching Sparky roadmap)</p>
<hr/>
<h2 id="references">References<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#references" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p><strong>DGX Spark Playbooks:</strong></p>
<ul>
<li><code>/home/beengud/raibid-labs/dgx-spark-playbooks/</code></li>
</ul>
<p><strong>Sparky Project:</strong></p>
<ul>
<li><code>/home/beengud/raibid-labs/sparky/</code></li>
</ul>
<p><strong>Models (HuggingFace):</strong></p>
<ul>
<li>meta-llama/Llama-3.1-8B-Instruct</li>
<li>Qwen/Qwen2.5-32B-Instruct</li>
<li>openai/gpt-oss-20b</li>
</ul>
<p><strong>OSS Tools:</strong></p>
<ul>
<li>Ollama: <a href="https://ollama.com" class="external">https://ollama.com<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></li>
<li>vLLM: <a href="https://github.com/vllm-project/vllm" class="external">https://github.com/vllm-project/vllm<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></li>
<li>TensorRT-LLM: <a href="https://github.com/NVIDIA/TensorRT-LLM" class="external">https://github.com/NVIDIA/TensorRT-LLM<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></li>
</ul></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div class="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false,&quot;enableRadial&quot;:false}"></div><button class="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div class="global-graph-outer"><div class="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.2,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true,&quot;enableRadial&quot;:true}"></div></div></div><div class="toc desktop-only"><button type="button" class="toc-header" aria-controls="toc-309" aria-expanded="true"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><ul id="list-1" class="toc-content overflow"><li class="depth-0"><a href="#sparky-oss-deployment-strategy-dgx-spark-infrastructure-analysis" data-for="sparky-oss-deployment-strategy-dgx-spark-infrastructure-analysis">Sparky OSS Deployment Strategy: DGX Spark Infrastructure Analysis</a></li><li class="depth-1"><a href="#executive-summary" data-for="executive-summary">Executive Summary</a></li><li class="depth-2"><a href="#key-finding" data-for="key-finding">Key Finding</a></li><li class="depth-1"><a href="#1-infrastructure-landscape" data-for="1-infrastructure-landscape">1. Infrastructure Landscape</a></li><li class="depth-2"><a href="#11-available-hardware--gpu-resources" data-for="11-available-hardware--gpu-resources">1.1 Available Hardware &amp; GPU Resources</a></li><li class="depth-2"><a href="#12-containerization--orchestration" data-for="12-containerization--orchestration">1.2 Containerization &amp; Orchestration</a></li><li class="depth-1"><a href="#2-llm-inference-options-100-oss" data-for="2-llm-inference-options-100-oss">2. LLM Inference Options (100% OSS)</a></li><li class="depth-2"><a href="#21-ollama-simplest-path" data-for="21-ollama-simplest-path">2.1 Ollama (Simplest Path)</a></li><li class="depth-2"><a href="#22-vllm-high-throughput-path" data-for="22-vllm-high-throughput-path">2.2 vLLM (High-Throughput Path)</a></li><li class="depth-2"><a href="#23-tensorrt-llm-maximum-efficiency" data-for="23-tensorrt-llm-maximum-efficiency">2.3 TensorRT-LLM (Maximum Efficiency)</a></li><li class="depth-1"><a href="#3-existing-deployment-patterns-ready-to-use" data-for="3-existing-deployment-patterns-ready-to-use">3. Existing Deployment Patterns (Ready to Use)</a></li><li class="depth-2"><a href="#31-pattern-1-text-to-knowledge-graph-txt2kg" data-for="31-pattern-1-text-to-knowledge-graph-txt2kg">3.1 Pattern 1: Text-to-Knowledge-Graph (txt2kg)</a></li><li class="depth-2"><a href="#32-pattern-2-multi-agent-chatbot" data-for="32-pattern-2-multi-agent-chatbot">3.2 Pattern 2: Multi-Agent Chatbot</a></li><li class="depth-2"><a href="#33-pattern-3-trt-llm-multi-node" data-for="33-pattern-3-trt-llm-multi-node">3.3 Pattern 3: TRT-LLM Multi-Node</a></li><li class="depth-1"><a href="#4-recommended-architecture-for-sparky-100-oss" data-for="4-recommended-architecture-for-sparky-100-oss">4. Recommended Architecture for Sparky (100% OSS)</a></li><li class="depth-2"><a href="#41-minimum-viable-deployment" data-for="41-minimum-viable-deployment">4.1 Minimum Viable Deployment</a></li><li class="depth-2"><a href="#42-production-deployment" data-for="42-production-deployment">4.2 Production Deployment</a></li><li class="depth-2"><a href="#43-enterprise-deployment" data-for="43-enterprise-deployment">4.3 Enterprise Deployment</a></li><li class="depth-1"><a href="#5-model-selection-for-sparky" data-for="5-model-selection-for-sparky">5. Model Selection for Sparky</a></li><li class="depth-2"><a href="#51-recommended-models-by-use-case" data-for="51-recommended-models-by-use-case">5.1 Recommended Models (By Use Case)</a></li><li class="depth-2"><a href="#52-model-performance-on-dgx-spark" data-for="52-model-performance-on-dgx-spark">5.2 Model Performance on DGX Spark</a></li><li class="depth-1"><a href="#6-integration-points-with-existing-infrastructure" data-for="6-integration-points-with-existing-infrastructure">6. Integration Points with Existing Infrastructure</a></li><li class="depth-2"><a href="#61-git-data-collection-unchanged" data-for="61-git-data-collection-unchanged">6.1 Git Data Collection (Unchanged)</a></li><li class="depth-2"><a href="#62-llm-processing-pipeline-new" data-for="62-llm-processing-pipeline-new">6.2 LLM Processing Pipeline (NEW)</a></li><li class="depth-2"><a href="#63-storage-strategy" data-for="63-storage-strategy">6.3 Storage Strategy</a></li><li class="depth-1"><a href="#7-deployment-patterns-ready-to-copy" data-for="7-deployment-patterns-ready-to-copy">7. Deployment Patterns (Ready to Copy)</a></li><li class="depth-2"><a href="#71-health-checks-from-txt2kg" data-for="71-health-checks-from-txt2kg">7.1 Health Checks (From txt2kg)</a></li><li class="depth-2"><a href="#72-gpu-resource-configuration-from-trt-llm" data-for="72-gpu-resource-configuration-from-trt-llm">7.2 GPU Resource Configuration (From TRT-LLM)</a></li><li class="depth-2"><a href="#73-multi-container-networks-from-multi-agent-chatbot" data-for="73-multi-container-networks-from-multi-agent-chatbot">7.3 Multi-Container Networks (From multi-agent-chatbot)</a></li><li class="depth-2"><a href="#74-volume-management-from-txt2kg" data-for="74-volume-management-from-txt2kg">7.4 Volume Management (From txt2kg)</a></li><li class="depth-1"><a href="#8-technology-stack-summary" data-for="8-technology-stack-summary">8. Technology Stack Summary</a></li><li class="depth-2"><a href="#81-core-components" data-for="81-core-components">8.1 Core Components</a></li><li class="depth-2"><a href="#82-external-dependencies-all-optional" data-for="82-external-dependencies-all-optional">8.2 External Dependencies (All Optional)</a></li><li class="depth-1"><a href="#9-path-forward-for-sparky" data-for="9-path-forward-for-sparky">9. Path Forward for Sparky</a></li><li class="depth-2"><a href="#phase-0-validation-days-1-2" data-for="phase-0-validation-days-1-2">Phase 0: Validation (Days 1-2)</a></li><li class="depth-2"><a href="#phase-1-integration-days-3-5" data-for="phase-1-integration-days-3-5">Phase 1: Integration (Days 3-5)</a></li><li class="depth-2"><a href="#phase-2-optimization-days-6-10" data-for="phase-2-optimization-days-6-10">Phase 2: Optimization (Days 6-10)</a></li><li class="depth-2"><a href="#phase-3-production-days-11-15" data-for="phase-3-production-days-11-15">Phase 3: Production (Days 11-15)</a></li><li class="depth-1"><a href="#10-key-advantages-of-this-approach" data-for="10-key-advantages-of-this-approach">10. Key Advantages of This Approach</a></li><li class="depth-1"><a href="#11-file-reference-map" data-for="11-file-reference-map">11. File Reference Map</a></li><li class="depth-2"><a href="#dgx-spark-playbooks-ready-to-use" data-for="dgx-spark-playbooks-ready-to-use">DGX Spark Playbooks (Ready to Use)</a></li><li class="depth-2"><a href="#sparky-project-structure-ready-for-implementation" data-for="sparky-project-structure-ready-for-implementation">Sparky Project Structure (Ready for Implementation)</a></li><li class="depth-1"><a href="#12-resource-requirements" data-for="12-resource-requirements">12. Resource Requirements</a></li><li class="depth-2"><a href="#minimum-deployment" data-for="minimum-deployment">Minimum Deployment</a></li><li class="depth-2"><a href="#recommended-production" data-for="recommended-production">Recommended (Production)</a></li><li class="depth-1"><a href="#13-risk-assessment" data-for="13-risk-assessment">13. Risk Assessment</a></li><li class="depth-1"><a href="#14-conclusion" data-for="14-conclusion">14. Conclusion</a></li><li class="depth-1"><a href="#references" data-for="references">References</a></li><li class="overflow-end"></li></ul></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.5.2</a> © 2025</p><ul><li><a href="https://github.com/raibid-labs">Raibid Labs</a></li><li><a href="https://github.com/raibid-labs/docs">Documentation Hub</a></li></ul></footer></div></div></body><script type="application/javascript">function n(){let t=this.parentElement;t.classList.toggle("is-collapsed");let e=t.getElementsByClassName("callout-content")[0];if(!e)return;let l=t.classList.contains("is-collapsed");e.style.gridTemplateRows=l?"0fr":"1fr"}function c(){let t=document.getElementsByClassName("callout is-collapsible");for(let e of t){let l=e.getElementsByClassName("callout-title")[0],s=e.getElementsByClassName("callout-content")[0];if(!l||!s)continue;l.addEventListener("click",n),window.addCleanup(()=>l.removeEventListener("click",n));let o=e.classList.contains("is-collapsed");s.style.gridTemplateRows=o?"0fr":"1fr"}}document.addEventListener("nav",c);
</script><script type="module">function f(i,e){if(!i)return;function r(o){o.target===this&&(o.preventDefault(),o.stopPropagation(),e())}function t(o){o.key.startsWith("Esc")&&(o.preventDefault(),e())}i?.addEventListener("click",r),window.addCleanup(()=>i?.removeEventListener("click",r)),document.addEventListener("keydown",t),window.addCleanup(()=>document.removeEventListener("keydown",t))}function y(i){for(;i.firstChild;)i.removeChild(i.firstChild)}var h=class{constructor(e,r){this.container=e;this.content=r;this.setupEventListeners(),this.setupNavigationControls(),this.resetTransform()}isDragging=!1;startPan={x:0,y:0};currentPan={x:0,y:0};scale=1;MIN_SCALE=.5;MAX_SCALE=3;cleanups=[];setupEventListeners(){let e=this.onMouseDown.bind(this),r=this.onMouseMove.bind(this),t=this.onMouseUp.bind(this),o=this.resetTransform.bind(this);this.container.addEventListener("mousedown",e),document.addEventListener("mousemove",r),document.addEventListener("mouseup",t),window.addEventListener("resize",o),this.cleanups.push(()=>this.container.removeEventListener("mousedown",e),()=>document.removeEventListener("mousemove",r),()=>document.removeEventListener("mouseup",t),()=>window.removeEventListener("resize",o))}cleanup(){for(let e of this.cleanups)e()}setupNavigationControls(){let e=document.createElement("div");e.className="mermaid-controls";let r=this.createButton("+",()=>this.zoom(.1)),t=this.createButton("-",()=>this.zoom(-.1)),o=this.createButton("Reset",()=>this.resetTransform());e.appendChild(t),e.appendChild(o),e.appendChild(r),this.container.appendChild(e)}createButton(e,r){let t=document.createElement("button");return t.textContent=e,t.className="mermaid-control-button",t.addEventListener("click",r),window.addCleanup(()=>t.removeEventListener("click",r)),t}onMouseDown(e){e.button===0&&(this.isDragging=!0,this.startPan={x:e.clientX-this.currentPan.x,y:e.clientY-this.currentPan.y},this.container.style.cursor="grabbing")}onMouseMove(e){this.isDragging&&(e.preventDefault(),this.currentPan={x:e.clientX-this.startPan.x,y:e.clientY-this.startPan.y},this.updateTransform())}onMouseUp(){this.isDragging=!1,this.container.style.cursor="grab"}zoom(e){let r=Math.min(Math.max(this.scale+e,this.MIN_SCALE),this.MAX_SCALE),t=this.content.getBoundingClientRect(),o=t.width/2,n=t.height/2,c=r-this.scale;this.currentPan.x-=o*c,this.currentPan.y-=n*c,this.scale=r,this.updateTransform()}updateTransform(){this.content.style.transform=`translate(${this.currentPan.x}px, ${this.currentPan.y}px) scale(${this.scale})`}resetTransform(){this.scale=1;let e=this.content.querySelector("svg");this.currentPan={x:e.getBoundingClientRect().width/2,y:e.getBoundingClientRect().height/2},this.updateTransform()}},C=["--secondary","--tertiary","--gray","--light","--lightgray","--highlight","--dark","--darkgray","--codeFont"],E;document.addEventListener("nav",async()=>{let e=document.querySelector(".center").querySelectorAll("code.mermaid");if(e.length===0)return;E||=await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.esm.min.mjs");let r=E.default,t=new WeakMap;for(let n of e)t.set(n,n.innerText);async function o(){for(let s of e){s.removeAttribute("data-processed");let a=t.get(s);a&&(s.innerHTML=a)}let n=C.reduce((s,a)=>(s[a]=window.getComputedStyle(document.documentElement).getPropertyValue(a),s),{}),c=document.documentElement.getAttribute("saved-theme")==="dark";r.initialize({startOnLoad:!1,securityLevel:"loose",theme:c?"dark":"base",themeVariables:{fontFamily:n["--codeFont"],primaryColor:n["--light"],primaryTextColor:n["--darkgray"],primaryBorderColor:n["--tertiary"],lineColor:n["--darkgray"],secondaryColor:n["--secondary"],tertiaryColor:n["--tertiary"],clusterBkg:n["--light"],edgeLabelBackground:n["--highlight"]}}),await r.run({nodes:e})}await o(),document.addEventListener("themechange",o),window.addCleanup(()=>document.removeEventListener("themechange",o));for(let n=0;n<e.length;n++){let v=function(){let g=l.querySelector("#mermaid-space"),m=l.querySelector(".mermaid-content");if(!m)return;y(m);let w=c.querySelector("svg").cloneNode(!0);m.appendChild(w),l.classList.add("active"),g.style.cursor="grab",u=new h(g,m)},M=function(){l.classList.remove("active"),u?.cleanup(),u=null},c=e[n],s=c.parentElement,a=s.querySelector(".clipboard-button"),d=s.querySelector(".expand-button"),p=window.getComputedStyle(a),L=a.offsetWidth+parseFloat(p.marginLeft||"0")+parseFloat(p.marginRight||"0");d.style.right=`calc(${L}px + 0.3rem)`,s.prepend(d);let l=s.querySelector("#mermaid-container");if(!l)return;let u=null;d.addEventListener("click",v),f(l,M),window.addCleanup(()=>{u?.cleanup(),d.removeEventListener("click",v)})}});
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="../../../postscript.js" type="module"></script></html>